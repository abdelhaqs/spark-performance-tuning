{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dynamic Partitioning Pruning\n",
    "- Pruning partitions at runtime\n",
    "- Problem Statement: Analyse the listening activity of users on the release date of a song on/after `2020-01-01`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = 'all'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e02171b5-8b8d-4b81-8826-2fb3ee1a8a24",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.storagelevel import StorageLevel\n",
    "from pyspark.sql.types import *\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = (\n",
    "    SparkSession\n",
    "    .builder\n",
    "    .config(\"spark.driver.memory\", \"10g\")\n",
    "    .master(\"local[*]\")\n",
    "    .appName(\"6_1_dynamic_partition_pruning\")\n",
    "    .getOrCreate()\n",
    ")\n",
    "sc = spark.sparkContext\n",
    "sc.setLogLevel(\"ERROR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_listening_actv = spark.read.csv(\"datasets/partitioning/raw/Spotify_Listening_Activity.csv\", header=True, inferSchema=True)\n",
    "df_listening_actv = (\n",
    "    df_listening_actv\n",
    "    .withColumnRenamed(\"listen_date\", \"listen_time\")\n",
    "    .withColumn(\"listen_date\", F.to_date(\"listen_time\", \"yyyy-MM-dd HH:mm:ss.SSSSSS\"))\n",
    ")\n",
    "\n",
    "# Partitioning listening activity by the listen date\n",
    "(\n",
    "    df_listening_actv\n",
    "    .write\n",
    "    .partitionBy(\"listen_date\")\n",
    "    .mode(\"overwrite\")\n",
    "    .parquet(\"datasets/partitioning/partitioned/listening_activity_pt\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-------+--------------------------+---------------+-----------+\n",
      "|activity_id|song_id|listen_time               |listen_duration|listen_date|\n",
      "+-----------+-------+--------------------------+---------------+-----------+\n",
      "|4456       |16     |2023-07-18 10:15:47.023264|151            |2023-07-18 |\n",
      "|4457       |65     |2023-07-18 10:15:47.023264|181            |2023-07-18 |\n",
      "|4458       |60     |2023-07-18 10:15:47.023264|280            |2023-07-18 |\n",
      "|4459       |3      |2023-07-18 10:15:47.023264|249            |2023-07-18 |\n",
      "|4460       |45     |2023-07-18 10:15:47.023264|130            |2023-07-18 |\n",
      "+-----------+-------+--------------------------+---------------+-----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_listening_actv_pt = spark.read.parquet(\"datasets/partitioning/partitioned/listening_activity_pt\")\n",
    "df_listening_actv_pt.show(5, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- song_id: integer (nullable = true)\n",
      " |-- title: string (nullable = true)\n",
      " |-- artist_id: integer (nullable = true)\n",
      " |-- release_date: timestamp (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_songs = spark.read.csv(\"datasets/partitioning/raw/Spotify_Songs.csv\", header=True, inferSchema=True)\n",
    "df_songs.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------+---------+--------------------------+------------+\n",
      "|song_id|title |artist_id|release_datetime          |release_date|\n",
      "+-------+------+---------+--------------------------+------------+\n",
      "|1      |Song_1|2        |2021-10-15 10:15:47.006571|2021-10-15  |\n",
      "|2      |Song_2|45       |2020-12-07 10:15:47.006588|2020-12-07  |\n",
      "|3      |Song_3|25       |2022-07-11 10:15:47.006591|2022-07-11  |\n",
      "|4      |Song_4|25       |2019-03-09 10:15:47.006593|2019-03-09  |\n",
      "|5      |Song_5|26       |2019-09-07 10:15:47.006596|2019-09-07  |\n",
      "+-------+------+---------+--------------------------+------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "root\n",
      " |-- song_id: integer (nullable = true)\n",
      " |-- title: string (nullable = true)\n",
      " |-- artist_id: integer (nullable = true)\n",
      " |-- release_datetime: timestamp (nullable = true)\n",
      " |-- release_date: date (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_songs = (\n",
    "    df_songs\n",
    "    .withColumnRenamed(\"release_date\", \"release_datetime\")\n",
    "    .withColumn(\"release_date\", F.to_date(\"release_datetime\", \"yyyy-MM-dd HH:mm:ss.SSSSSS\"))\n",
    ")\n",
    "df_songs.show(5, False)\n",
    "df_songs.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pick songs released in 2020\n",
    "df_selected_songs = df_songs.filter(F.col(\"release_date\") > F.lit(\"2019-12-31\"))\n",
    "\n",
    "\n",
    "df_listening_actv_of_selected_songs = df_listening_actv_pt.join(\n",
    "    df_selected_songs, \n",
    "    on=(df_songs.release_date == df_listening_actv_pt.listen_date) & (df_songs.song_id == df_listening_actv_pt.song_id), \n",
    "    how=\"inner\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Parsed Logical Plan ==\n",
      "Join Inner, ((release_date#109 = listen_date#50) AND (song_id#95 = song_id#47))\n",
      ":- Relation [activity_id#46,song_id#47,listen_time#48,listen_duration#49,listen_date#50] parquet\n",
      "+- Filter (release_date#109 > cast(2019-12-31 as date))\n",
      "   +- Project [song_id#95, title#96, artist_id#97, release_datetime#103, to_date(release_datetime#103, Some(yyyy-MM-dd HH:mm:ss.SSSSSS), Some(Etc/UTC), false) AS release_date#109]\n",
      "      +- Project [song_id#95, title#96, artist_id#97, release_date#98 AS release_datetime#103]\n",
      "         +- Relation [song_id#95,title#96,artist_id#97,release_date#98] csv\n",
      "\n",
      "== Analyzed Logical Plan ==\n",
      "activity_id: int, song_id: int, listen_time: timestamp, listen_duration: int, listen_date: date, song_id: int, title: string, artist_id: int, release_datetime: timestamp, release_date: date\n",
      "Join Inner, ((release_date#109 = listen_date#50) AND (song_id#95 = song_id#47))\n",
      ":- Relation [activity_id#46,song_id#47,listen_time#48,listen_duration#49,listen_date#50] parquet\n",
      "+- Filter (release_date#109 > cast(2019-12-31 as date))\n",
      "   +- Project [song_id#95, title#96, artist_id#97, release_datetime#103, to_date(release_datetime#103, Some(yyyy-MM-dd HH:mm:ss.SSSSSS), Some(Etc/UTC), false) AS release_date#109]\n",
      "      +- Project [song_id#95, title#96, artist_id#97, release_date#98 AS release_datetime#103]\n",
      "         +- Relation [song_id#95,title#96,artist_id#97,release_date#98] csv\n",
      "\n",
      "== Optimized Logical Plan ==\n",
      "Join Inner, ((release_date#109 = listen_date#50) AND (song_id#95 = song_id#47))\n",
      ":- Filter ((isnotnull(listen_date#50) AND isnotnull(song_id#47)) AND dynamicpruning#160 [listen_date#50])\n",
      ":  :  +- Project [song_id#95, title#96, artist_id#97, release_date#98 AS release_datetime#103, cast(gettimestamp(release_date#98, yyyy-MM-dd HH:mm:ss.SSSSSS, TimestampType, Some(Etc/UTC), false) as date) AS release_date#109]\n",
      ":  :     +- Filter ((gettimestamp(release_date#98, yyyy-MM-dd HH:mm:ss.SSSSSS, TimestampType, Some(Etc/UTC), false) >= 2020-01-01 00:00:00) AND (isnotnull(cast(gettimestamp(release_date#98, yyyy-MM-dd HH:mm:ss.SSSSSS, TimestampType, Some(Etc/UTC), false) as date)) AND isnotnull(song_id#95)))\n",
      ":  :        +- Relation [song_id#95,title#96,artist_id#97,release_date#98] csv\n",
      ":  +- Relation [activity_id#46,song_id#47,listen_time#48,listen_duration#49,listen_date#50] parquet\n",
      "+- Project [song_id#95, title#96, artist_id#97, release_date#98 AS release_datetime#103, cast(gettimestamp(release_date#98, yyyy-MM-dd HH:mm:ss.SSSSSS, TimestampType, Some(Etc/UTC), false) as date) AS release_date#109]\n",
      "   +- Filter ((gettimestamp(release_date#98, yyyy-MM-dd HH:mm:ss.SSSSSS, TimestampType, Some(Etc/UTC), false) >= 2020-01-01 00:00:00) AND (isnotnull(cast(gettimestamp(release_date#98, yyyy-MM-dd HH:mm:ss.SSSSSS, TimestampType, Some(Etc/UTC), false) as date)) AND isnotnull(song_id#95)))\n",
      "      +- Relation [song_id#95,title#96,artist_id#97,release_date#98] csv\n",
      "\n",
      "== Physical Plan ==\n",
      "AdaptiveSparkPlan isFinalPlan=false\n",
      "+- BroadcastHashJoin [listen_date#50, song_id#47], [release_date#109, song_id#95], Inner, BuildRight, false\n",
      "   :- Filter isnotnull(song_id#47)\n",
      "   :  +- FileScan parquet [activity_id#46,song_id#47,listen_time#48,listen_duration#49,listen_date#50] Batched: true, DataFilters: [isnotnull(song_id#47)], Format: Parquet, Location: InMemoryFileIndex(1 paths)[file:/home/jovyan/work/notebooks/datasets/partitioning/partitioned/lis..., PartitionFilters: [isnotnull(listen_date#50), dynamicpruningexpression(listen_date#50 IN dynamicpruning#160)], PushedFilters: [IsNotNull(song_id)], ReadSchema: struct<activity_id:int,song_id:int,listen_time:timestamp,listen_duration:int>\n",
      "   :        +- SubqueryAdaptiveBroadcast dynamicpruning#160, 0, true, Project [song_id#95, title#96, artist_id#97, release_date#98 AS release_datetime#103, cast(gettimestamp(release_date#98, yyyy-MM-dd HH:mm:ss.SSSSSS, TimestampType, Some(Etc/UTC), false) as date) AS release_date#109], [release_date#109, song_id#95]\n",
      "   :           +- AdaptiveSparkPlan isFinalPlan=false\n",
      "   :              +- Project [song_id#95, title#96, artist_id#97, release_date#98 AS release_datetime#103, cast(gettimestamp(release_date#98, yyyy-MM-dd HH:mm:ss.SSSSSS, TimestampType, Some(Etc/UTC), false) as date) AS release_date#109]\n",
      "   :                 +- Filter (((gettimestamp(release_date#98, yyyy-MM-dd HH:mm:ss.SSSSSS, TimestampType, Some(Etc/UTC), false) >= 2020-01-01 00:00:00) AND isnotnull(cast(gettimestamp(release_date#98, yyyy-MM-dd HH:mm:ss.SSSSSS, TimestampType, Some(Etc/UTC), false) as date))) AND isnotnull(song_id#95))\n",
      "   :                    +- FileScan csv [song_id#95,title#96,artist_id#97,release_date#98] Batched: false, DataFilters: [(gettimestamp(release_date#98, yyyy-MM-dd HH:mm:ss.SSSSSS, TimestampType, Some(Etc/UTC), false) ..., Format: CSV, Location: InMemoryFileIndex(1 paths)[file:/home/jovyan/work/notebooks/datasets/partitioning/raw/Spotify_Son..., PartitionFilters: [], PushedFilters: [IsNotNull(song_id)], ReadSchema: struct<song_id:int,title:string,artist_id:int,release_date:timestamp>\n",
      "   +- BroadcastExchange HashedRelationBroadcastMode(List(input[4, date, true], input[0, int, true]),false), [plan_id=121]\n",
      "      +- Project [song_id#95, title#96, artist_id#97, release_date#98 AS release_datetime#103, cast(gettimestamp(release_date#98, yyyy-MM-dd HH:mm:ss.SSSSSS, TimestampType, Some(Etc/UTC), false) as date) AS release_date#109]\n",
      "         +- Filter (((gettimestamp(release_date#98, yyyy-MM-dd HH:mm:ss.SSSSSS, TimestampType, Some(Etc/UTC), false) >= 2020-01-01 00:00:00) AND isnotnull(cast(gettimestamp(release_date#98, yyyy-MM-dd HH:mm:ss.SSSSSS, TimestampType, Some(Etc/UTC), false) as date))) AND isnotnull(song_id#95))\n",
      "            +- FileScan csv [song_id#95,title#96,artist_id#97,release_date#98] Batched: false, DataFilters: [(gettimestamp(release_date#98, yyyy-MM-dd HH:mm:ss.SSSSSS, TimestampType, Some(Etc/UTC), false) ..., Format: CSV, Location: InMemoryFileIndex(1 paths)[file:/home/jovyan/work/notebooks/datasets/partitioning/raw/Spotify_Son..., PartitionFilters: [], PushedFilters: [IsNotNull(song_id)], ReadSchema: struct<song_id:int,title:string,artist_id:int,release_date:timestamp>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_listening_actv_of_selected_songs.explain(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-------+--------------------+---------------+-----------+-------+-------+---------+--------------------+------------+\n",
      "|activity_id|song_id|         listen_time|listen_duration|listen_date|song_id|  title|artist_id|    release_datetime|release_date|\n",
      "+-----------+-------+--------------------+---------------+-----------+-------+-------+---------+--------------------+------------+\n",
      "|       9760|     89|2023-07-24 10:15:...|             81| 2023-07-24|     89|Song_89|       33|2023-07-24 10:15:...|  2023-07-24|\n",
      "|       9768|     89|2023-07-24 10:15:...|            295| 2023-07-24|     89|Song_89|       33|2023-07-24 10:15:...|  2023-07-24|\n",
      "|       9799|     89|2023-07-24 10:15:...|            272| 2023-07-24|     89|Song_89|       33|2023-07-24 10:15:...|  2023-07-24|\n",
      "|       7322|     64|2023-10-25 10:15:...|             95| 2023-10-25|     64|Song_64|       32|2023-10-25 10:15:...|  2023-10-25|\n",
      "+-----------+-------+--------------------+---------------+-----------+-------+-------+---------+--------------------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_listening_actv_of_selected_songs.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "data-skew-explanation",
   "notebookOrigID": 4018749166498458,
   "widgets": {}
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
